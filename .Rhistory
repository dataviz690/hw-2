run_pca_by_position <- function(data, pos_label) {
data_pos <- data |> filter(.data[[pos_label]] == 1)
rec <- recipe(~ ., data = data_pos) |>
step_normalize(contains("pr90")) |>
step_pca(contains("pr90"),
id = "pca",
keep_original_cols = TRUE) |>
prep()
pve <- tidy(rec, id = "pca", type = "variance") |>
filter(terms == "percent variance") |>
mutate(position = pos_label)
loadings <- tidy(rec, id = "pca", type = "coef") |>
filter(component %in% c("PC1", "PC2")) |>
mutate(position = pos_label)
list(pve = pve, loadings = loadings)
}
#
positions <- c("DF", "MF", "FW", "GK")
pca_by_pos <- map(positions, ~ run_pca_by_position(mls22, .x))
library(tidymodels)
library(purrr)
library(dplyr)
library(tidyr)
library(ggplot2)
run_pca_by_position <- function(data, pos_label) {
data_pos <- data |> filter(.data[[pos_label]] == 1)
rec <- recipe(~ ., data = data_pos) |>
step_normalize(contains("pr90")) |>
step_pca(contains("pr90"),
id = "pca",
keep_original_cols = TRUE) |>
prep()
pve <- tidy(rec, id = "pca", type = "variance") |>
filter(terms == "percent variance") |>
mutate(position = pos_label)
loadings <- tidy(rec, id = "pca", type = "coef") |>
filter(component %in% c("PC1", "PC2")) |>
mutate(position = pos_label)
list(pve = pve, loadings = loadings)
}
#
positions <- c("DF", "MF", "FW", "GK")
pca_by_pos <- map(positions, ~ run_pca_by_position(mls22_baked, .x))
library(tidyverse)
library(tidymodels)
library(purrr)
# 1) Helper to remove any existing PC columns (plain "PC1"… or prefixed like "DF_PC1")
strip_pc_cols <- function(df) {
df %>% select(-matches("(^PC\\d+$)|([A-Z]{2}_PC\\d+$)"))
}
# If you previously created mls22_baked, start from a "clean" copy
mls22_clean <- strip_pc_cols(mls22_baked)  # or just use `mls22` if that's untouched
# 2) Position PCA helper with UNIQUE prefix per position to avoid future collisions
run_pca_by_position <- function(data, pos_label) {
data_pos <- data %>% filter(.data[[pos_label]] == 1) %>% strip_pc_cols()
rec <- recipe(~ ., data = data_pos) %>%
step_normalize(contains("pr90")) %>%
step_pca(
contains("pr90"),
id = "pca",
keep_original_cols = TRUE,
prefix = paste0(pos_label, "_PC")  # <-- unique names like DF_PC1, MF_PC1, ...
) %>%
prep()
list(
pve = tidy(rec, id = "pca", type = "variance") %>%
filter(terms == "percent variance") %>%
mutate(position = pos_label),
loadings = tidy(rec, id = "pca", type = "coef") %>%
filter(component %in% c(paste0(pos_label, "_PC1"), paste0(pos_label, "_PC2"))) %>%
mutate(position = pos_label)
)
}
positions <- c("DF", "MF", "FW", "GK")
pca_by_pos <- map(positions, ~ run_pca_by_position(mls22_clean, .x))
# 3) Combine & plot
pve_all <- map_dfr(pca_by_pos, "pve")
loadings_all <- map_dfr(pca_by_pos, "loadings")
# Scree plot by position
ggplot(pve_all, aes(x = component, y = value, group = position, color = position)) +
geom_line() +
geom_point() +
labs(title = "Scree Plot by Position", x = "Component", y = "Percent Variance Explained") +
theme_bw()
# Loadings table (PC1/PC2 per position)
loadings_all %>%
select(position, terms, component, value) %>%
pivot_wider(names_from = component, values_from = value) %>%
arrange(position)
library(tidyverse)
library(tidymodels)
library(purrr)
strip_pc_cols <- function(df) {
df %>% select(-matches("(^PC\\d+$)|([A-Z]{2}_PC\\d+$)"))
}
mls22_clean <- strip_pc_cols(mls22_baked)
run_pca_by_position <- function(data, pos_label) {
data_pos <- data %>% filter(.data[[pos_label]] == 1) %>% strip_pc_cols()
rec <- recipe(~ ., data = data_pos) %>%
step_normalize(contains("pr90")) %>%
step_pca(
contains("pr90"),
id = "pca",
keep_original_cols = TRUE,
prefix = paste0(pos_label, "_PC")
) %>%
prep()
list(
pve = tidy(rec, id = "pca", type = "variance") %>%
filter(terms == "percent variance") %>%
mutate(position = pos_label),
loadings = tidy(rec, id = "pca", type = "coef") %>%
filter(component %in% c(paste0(pos_label, "_PC1"), paste0(pos_label, "_PC2"))) %>%
mutate(position = pos_label)
)
}
positions <- c("DF", "MF", "FW", "GK")
pca_by_pos <- map(positions, ~ run_pca_by_position(mls22_clean, .x))
loadings_all <- map_dfr(pca_by_pos, "loadings")
ggplot(pve_all, aes(x = component, y = value, group = position, color = position)) +
geom_line() +
geom_point() +
labs(title = "Scree Plot by Position", x = "Component", y = "Percent Variance Explained") +
theme_bw()
loadings_all %>%
select(position, terms, component, value) %>%
pivot_wider(names_from = component, values_from = value) %>%
arrange(position)
install.packages("brulee")
library(tidymodels)
library(brulee)
nnet_rec <- recipe(high_chol ~ ., data = nhanes18_train) |>
# drop rows where we don't have outcome info (what's the consequence?)
step_naomit(high_chol) |>
# impute missing values using a forest ensemble
step_impute_bag(all_predictors()) |>
# turn all categorical predictors into dummies
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
# remove zero variance predictors
step_zv(all_predictors()) |>
# normalize all numeric predictors
step_normalize(all_numeric_predictors())
#| message: false
#| warning: false
library(reticulate)
library(tidyverse)
library(haven)
# import data here
demo <- read_xpt("DEMO_J.xpt")
cons_beh <- read_xpt("CBQ_J.xpt")
tchol <- read_xpt("TCHOL_J.xpt")
# joining together
nhanes18 <- tchol |>
left_join(cons_beh, by = "SEQN") |>
left_join(demo, by = "SEQN")
# creating high cholesterol indicator + do some ease of use changes
nhanes18 <- nhanes18 |>
mutate(high_chol = factor(if_else(LBXTC >= 200, "high", "normal"),
levels = c("normal", "high")),
pir = INDFMPIR,
sp_super_groc = if_else(CBD071 > 8400, NA, CBD071),
sp_nonfood = if_else(CBD091 > 8400, NA, CBD091),
sp_food_other = if_else(CBD111 > 8400, NA, CBD111),
sp_food_out = if_else(CBD121 > 8400, NA, CBD121),
sp_food_carryout = if_else(CBD131 > 8400, NA, CBD131),
age = RIDAGEYR,
gender = factor(RIAGENDR, levels = c(1, 2),
labels = c("male", "female")),
race_eth3 = factor(RIDRETH3,
levels = c(1:4, 6:7),
labels = c(
"Mexican American",
"Other Hispanic",
"Non-Hispanic White",
"Non-Hispanic Black",
"Non-Hispanic Asian",
"Other Race/Multi-Racial"
)),
country_born = factor(DMDBORN4,
levels = c(1, 2),
labels = c("US States, DC",
"Other")),
citizen = factor(DMDCITZN,
levels = c(1, 2),
labels = c("US", "Other")),
educ = factor(DMDEDUC2,
levels = 1:5,
labels = c(
"Less than 9th grade",
"9-11th grade (includes 12th grade with no diploma)",
"High school graduate/GED or equivalent",
"Some college or AA degree",
"College graduate or above"
))) |>
relocate(high_chol, .after = SEQN)
nhanes18 <- nhanes18 |>
select(high_chol, pir:educ)
set.seed(756)
nhanes18 <- nhanes18 |>
mutate(test = sample(c(rep(1, times = round(n() * 0.25)),
rep(0, times = round(n() * 0.75))),
n(), replace = FALSE))
#| message: false
#| warning: false
# make train test split
nhanes18_train <- nhanes18 |>
filter(test == 0) |>
select(-test)
nhanes18_test <- nhanes18 |>
filter(test == 1) |>
select(-test)
library(tidymodels)
library(brulee)
nnet_rec <- recipe(high_chol ~ ., data = nhanes18_train) |>
# drop rows where we don't have outcome info (what's the consequence?)
step_naomit(high_chol) |>
# impute missing values using a forest ensemble
step_impute_bag(all_predictors()) |>
# turn all categorical predictors into dummies
step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
# remove zero variance predictors
step_zv(all_predictors()) |>
# normalize all numeric predictors
step_normalize(all_numeric_predictors())
library(tidygraph)
install.packages("tidygraph")
library(tidygraph)
library(ggraph)
install.packages("ggraph")
library(tidygraph)
library(ggraph)
library(tidyverse)
# ---- PARAMETERS ----
n_input  <- 5    # change to your number of predictors
n_h1     <- 12   # first hidden layer
n_h2     <- 6    # second hidden layer
n_output <- 1    # output layer (regression)
# ---- BUILD NODES ----
nodes <- tibble(
id = 1:(n_input + n_h1 + n_h2 + n_output),
layer = c(
rep("Input", n_input),
rep("Hidden1", n_h1),
rep("Hidden2", n_h2),
rep("Output", n_output)
)
)
# assign x/y positions (so layers line up visually)
nodes <- nodes %>%
group_by(layer) %>%
mutate(
x = case_when(
layer == "Input"   ~ 1,
layer == "Hidden1" ~ 2,
layer == "Hidden2" ~ 3,
layer == "Output"  ~ 4
),
y = seq(from = 1, to = n(), length.out = n())
) %>%
ungroup()
# ---- BUILD EDGES ----
edges <- bind_rows(
# Input → Hidden 1
expand_grid(
from = nodes$id[nodes$layer == "Input"],
to   = nodes$id[nodes$layer == "Hidden1"]
),
# Hidden 1 → Hidden 2
expand_grid(
from = nodes$id[nodes$layer == "Hidden1"],
to   = nodes$id[nodes$layer == "Hidden2"]
),
# Hidden 2 → Output
expand_grid(
from = nodes$id[nodes$layer == "Hidden2"],
to   = nodes$id[nodes$layer == "Output"]
)
)
# ---- CREATE GRAPH ----
g <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)
# ---- PLOT ----
ggraph(g, layout = "manual", x = x, y = y) +
geom_edge_link(alpha = 0.3, arrow = arrow(length = unit(2, "mm"))) +
geom_node_point(aes(color = layer), size = 8) +
geom_node_text(aes(label = layer), repel = TRUE, size = 3) +
scale_color_manual(values = c(
Input = "#1F77B4",
Hidden1 = "#FF7F0E",
Hidden2 = "#2CA02C",
Output = "#D62728"
)) +
theme_void() +
ggtitle("Two-Layer Neural Network Diagram (tidygraph + ggraph)")
insta
View(nhanes18_train)
library(tidygraph)
library(ggraph)
library(tidyverse)
#I found how to do this on stackoverflow
# ---- define PARAMETERS ----
n_input  <- 12    # number of predictors
n_h1     <- 12   # first hidden layer
n_h2     <- 6    # second hidden layer
n_output <- 1    # output layer
# ---- create NODES ----
nodes <- tibble(
id = 1:(n_input + n_h1 + n_h2 + n_output),
layer = c(
rep("Input", n_input),
rep("Hidden1", n_h1),
rep("Hidden2", n_h2),
rep("Output", n_output)
)
)
# assign x/y positions
nodes <- nodes %>%
group_by(layer) %>%
mutate(
x = case_when(
layer == "Input"   ~ 1,
layer == "Hidden1" ~ 2,
layer == "Hidden2" ~ 3,
layer == "Output"  ~ 4
),
y = seq(from = 1, to = n(), length.out = n())
) %>%
ungroup()
# ---- BUILD EDGES ----
edges <- bind_rows(
# Input → Hidden 1
expand_grid(
from = nodes$id[nodes$layer == "Input"],
to   = nodes$id[nodes$layer == "Hidden1"]
),
# Hidden 1 → Hidden 2
expand_grid(
from = nodes$id[nodes$layer == "Hidden1"],
to   = nodes$id[nodes$layer == "Hidden2"]
),
# Hidden 2 → Output
expand_grid(
from = nodes$id[nodes$layer == "Hidden2"],
to   = nodes$id[nodes$layer == "Output"]
)
)
# ---- CREATE GRAPH ----
g <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)
# ---- PLOT ----
ggraph(g, layout = "manual", x = x, y = y) +
geom_edge_link(alpha = 0.3, arrow = arrow(length = unit(2, "mm"))) +
geom_node_point(aes(color = layer), size = 8) +
geom_node_text(aes(label = layer), repel = TRUE, size = 3) +
scale_color_manual(values = c(
Input = "#1F77B4",
Hidden1 = "#FF7F0E",
Hidden2 = "#2CA02C",
Output = "#D62728"
)) +
theme_void() +
ggtitle("Neural Network Diagram")
insta
set.seed(756)
nnet_fit <- nnet_rec |>
brulee_mlp(data = nhanes18_train,
hidden_units = c(12, 6),
batch_size = 256,
class_weights = c(normal = 1, high = 3),
validation = 0.1,
activation = "relu",
penalty = 0.001,
learn_rate = 0.00001,
optimizer = "SGD",
dropout = 0.3,
epochs = 100,
#verbose = TRUE
)
#| eval: false
# ^ change to eval: true to display in rendered output
nhanes18_test_aug <- predict(nnet_fit,
new_data = nhanes18_test,
type = "class") |>
bind_cols(nhanes18_test)
nhanes18_test_aug |>
f_meas(high_chol,
.pred_class,
event_level = "second")
nhanes18_test_aug |>
conf_mat(high_chol,
.pred_class)
set.seed(756)
nnet_fit_3layer <- nnet_rec |>
brulee_mlp(data = nhanes18_train,
hidden_units = c(12, 6, 3),
batch_size = 256,
class_weights = c(normal = 1, high = 3),
validation = 0.1,
activation = "relu",
penalty = 0.001,
learn_rate = 0.00001,
optimizer = "SGD",
dropout = 0.3,
epochs = 100,
#verbose = TRUE
)
nhanes18_test_aug_nnet3 <- predict(nnet_fit_3layer,
new_data = nhanes18_test,
type = "class") |>
bind_cols(nhanes18_test)
nhanes18_test_aug_nnet3 |>
f_meas(high_chol,
.pred_class,
event_level = "second")
nhanes18_test_aug_nnet3 |>
conf_mat(high_chol,
.pred_class)
set.seed(756)
nnet_fit_3layer <- nnet_rec |>
brulee_mlp(data = nhanes18_train,
hidden_units = c(12, 6, 3),
batch_size = 256,
class_weights = c(normal = 1, high = 3),
validation = 0.1,
activation = "relu",
penalty = 0.001,
learn_rate = 0.00001,
optimizer = "SGD",
dropout = 0.3,
epochs = 100,
#verbose = TRUE
)
nhanes18_test_aug_nnet_3layer <- predict(nnet_fit_3layer,
new_data = nhanes18_test,
type = "class") |>
bind_cols(nhanes18_test)
nhanes18_test_aug_nnet_3layer |>
f_meas(high_chol,
.pred_class,
event_level = "second")
nhanes18_test_aug_nnet_3layer |>
conf_mat(high_chol,
.pred_class)
set.seed(756)
nnet_fit_3layer <- nnet_rec |>
brulee_mlp(data = nhanes18_train,
hidden_units = c(12, 6),
batch_size = 256,
class_weights = c(normal = 1, high = 15),
validation = 0.1,
activation = "relu",
penalty = 0.001,
learn_rate = 0.00001,
optimizer = "SGD",
dropout = 0.3,
epochs = 100,
#verbose = TRUE
)
nhanes18_test_aug_nnet_3layer <- predict(nnet_fit_3layer,
new_data = nhanes18_test,
type = "class") |>
bind_cols(nhanes18_test)
nhanes18_test_aug_nnet_3layer |>
f_meas(high_chol,
.pred_class,
event_level = "second")
nhanes18_test_aug_nnet_3layer |>
conf_mat(high_chol,
.pred_class)
file.exists("models/scf_resamples.rds")
readRDS("models/scf_resamples.rds")
try(readRDS("models/scf_resamples.rds"))
getwd()
list.files()
list.files("models")
file.exists("models/scf_resamples.rds")
getwd()
list.files("models")
file.exists("models/scf_resamples.rds")
getwd()
library(ggplot2)
?
ggplot2
demo()
data()
data(package = .packages(all.available = TRUE))
?yardstck
?yardstick()
library(yardstick)
?yardstick
library(ggplot2)
p <- ggplot(mpg, aes())
p
head(mph)
head(mpg)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
plot(pressure)
summary(cars)
print(cars)
summary(cars)
print(cars)
summary(mtcars)
print(cars)
?flexdashboard
library(flexdashboard) # always
?flexdashboard
?flexdashboard
install.packages("ggplot2")
install.packages("tidyverse")
packageVersion("ggplot2")
getwd()
setwd("C:/Users/lgianetti/OneDrive - City of Cambridge/DACSS Program/690V_data_viz/hw-2")
